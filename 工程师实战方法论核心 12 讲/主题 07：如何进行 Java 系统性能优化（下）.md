## 主题 07：如何进行 Java 系统性能优化（下）

### 1. 引言

系统性能优化涉及面非常广，涵盖方案优化、编码优化、并发优化、JVM 调优等诸多方面的知识。

虽然不同系统的优化策略存在差异，但从全局来看，它们的共性仍是主要的。首先，我们可以从方案设计、编码、并发设计、JVM 等方面去优化我们的系统；然后，可以通过一些 Linux 系统命令和工具去发现系统的性能瓶颈；最后，结合业务特点采用缓存、异步化、并发等方式对系统进行“定制”优化。

**本文为“Java 系统性能优化系列”的下篇，主要内容如下：**

1. 系统优化之并发设计优化
2. 系统优化之 JVM 调优
3. 系统优化之缓存设计

### 2. 系统优化—并发设计优化

并发程序设计（concurrent programming）是指由若干个可同时执行的程序模块组成程序的程序设计方法。采用并发程序设计可以使外围设备和处理器并行工作，缩短程序执行时间，提高计算机系统效率。

#### **2.1 并行设计模式**

并发场景中，常用的 Java 多线程设计模式包括：Future 模式、Master-Worker 模式、Guarded Suspension 模式、不变模式和生产者—消费者模式等。

**Future 模式**

Future 模式的核心在于：去除了主函数的等待时间，并使得原本需要等待的时间段可以用于处理其它业务逻辑。鉴于 Future 模式在多线程中高频使用，JDK 中内置了 Future 模式的实现。这些类在 java.util.concurrent 包里面。其中最为重要的是 FutureTask 类，它实现了 Runnable 接口，作为单独的线程运行。在其 run() 方法中，通过 Sync 内部类调用Callable 接口，并维护 Callable 接口的返回对象。当使用 FutureTask.get() 方法时，将返回Callable 接口的返回对象。

**Master-Worker 模式**

Master-Worker 模式是常用的并行模式之一，它的核心思想是：系统由两类进程协同工作，即 Master 进程和 Worker 进程，Master 负责接收和分配任务，Wroker 负责处理子任务。当各个 Worker 进程将子任务处理完成后，将结果返回给 Master 进程，由 Master 进程进行汇总，从而得到最终的结果，如下图所示：

![enter image description here](https://images.gitbook.cn/70fe97e0-0659-11e9-9218-75dc7589921f)

Master-Worker 模式的好处，它能够将一个大任务分解成若干个小任务并行执行，从而提高系统的吞吐量。而对于系统请求者 Client 来说，任务一旦提交，Master 进程会分配任务并立即返回，并不会等待系统全部处理完成后再返回，其处理过程是异步的。因此，Client不会出现等待现象。

**Guarded Suspension 模式**

Guarded Suspension 意为保护暂停。其核心思想是仅当服务进程准备好时，才提供服务。设想一种场景，服务器可能会在很短时间内承受大量的客户端请求，客户端请求的数量可能超过服务器本身的即时处理能力，而服务端程序又不能丢弃任何一个客户请求。此时，最佳的处理方案莫过于让客户端要求进行排队，由服务端程序一个接一个处理。这样，既保证了所有的客户端请求均不丢失，同时也避免了服务器由于同时处理太多的请求而崩溃。

**不变模式**

一个对象的状态在对象被创建之后就不再变化，这就是所谓的不变模式。在并发设计中，为确保数据的一致性和正确性，有必要对对象进行同步，但是同步操作对系统性能有相当的损耗。因此可以使用一种不可改变的对象，依靠其不变性来确保并发操作在没有同步的情况下依旧保持一致性和正确性。不变模式的使用场景主要包括两个条件：

- 当对象创建后，其内部状态和数据不再发生任何改变；
- 对象需求被共享、被多线程频繁访问。

JDK 中不变模式的使用也非常广泛。其中最为典型的是 java.lang.String，此外还有元数据的包装类，如：java.lang.Double、java.lang.Integer、java.lang.Boolean 等等。

**生产者消费者模式**

生产者—消费者模式是一个经典的多线程设计模式，它为多线程的协作提供了良好的解决方案。在生产者—消费者模式中，通常有两类线程，即若干个生产者线程和若干个消费者线程。生产者线程负责提交用户请求，消费者线程负责处理用户请求。生产者和消费者之间通过共享内存缓冲区进行通信。

生产者—消费者模式中的内存缓冲区的主要功能是数据在多线程间的共享。此外，通过该缓冲区，可以缓解生产者和消费者之间的性能差。

#### **2.2 多任务执行框架**

**Executors**

为了更好地控制多线程，JDK 提供了一套线程框架 Executor，它在 Java.util.concurrent 包中，是 JDK 并发包的核心。Executors 扮演线程工厂的角色，其创建线程的方法如下。

- **newFixedThreadPool()**

创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序（FIFO、LIFO、优先级）执行。

- **newSingleThreadPool()**

创建一个线程池，若线程空闲则立即执行，否则暂缓到队列中。

- **newCachedThreadPool()**

返回一个可根据实际情况调整线程个数的线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

- **newScheduledThreadPool()**

返回一个 ScheduledExecutorService 对象，支持定时及周期性任务执行。

若 Executors 工厂类无法满足我们的需求，可以自己去创建自定义的线程池。自定义线程池的构造方法如下：

```Java
public ThreadPoolExecutor(int corePoolSize,//核心线程数
                          int maximumPoolSize,//最大线程数
                          long keepAliveTime,//线程的空闲时间
                          TimeUnit unit,//给定单元粒度的时间段 
                          BlockingQueue<Runnable> workQueue,//有界、无界队列
                          RejectedExecutoionHandler handler//任务拒绝策略
                          ){.....}
```

**Condtion**

在 Java 中，任意一个对象都拥有一组定义在 java.lang.Object 上监视器方法，包括 wait()、wait(long timeout)、notify()、notifyAll()，这些方法配合 synchronized 关键字一起使用可以实现等待/通知模式。同样，Condition 接口也提供了与 Object 类似的监视器方法，并通过与 Lock 配合来实现等待/通知模式。

```Java
    public class UseCondition {

        private Lock lock = new ReentrantLock();
        private Condition condition = lock.newCondition();

        public void method1(){
            try {
                lock.lock();
                System.out.println("当前线程：" + 
    Thread.currentThread().getName() + "进入等待状态..");
                Thread.sleep(3000);
                System.out.println("当前线程：" + 
    Thread.currentThread().getName() + "释放锁..");
                // 调用await()，插入线程释放锁进入等待
                condition.await(); 
                System.out.println("当前线程：" + 
    Thread.currentThread().getName() +"继续执行...");
                // 调用signal()通知等待在condition上的线程
                condition.signal();  
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                lock.unlock();
            }
        }
    }
```

不难看出，Condition 的使用方式是比较简单的，需要注意的是使用 Condition 的等待/通知需要提前获取到与 Condition 对象关联的锁，Condition 对象由 Lock 对象创建。

**Semaphore**

Semaphore 中文含义是信号、信号系统。Semaphore 是一个线程同步的辅助类，可以维护当前访问自身的线程个数，并提供了同步机制。使用 Semaphore 可以控制同时访问资源的线程个数，例如，实现一个文件允许的并发访问数。

**ThreadLocal**

ThreadLocal 一般称为线程本地变量，它是一种特殊的线程绑定机制，将变量与线程绑定在一起，为每一个线程维护一个独立的变量副本。通过 ThreadLocal 可以将对象的可见范围限制在同一个线程内。

#### **2.3 锁控制**

并发问题产生的两个条件：

1. 数据被多线程共享
2. 数据会改变

只有这两个条件同时成立才可能出现多线程并发问题。上文中提到的“不变模式”就是通过破坏条件 2 来达到线程安全。而如果条件 2 无法实现，唯一的办法就是锁，锁可以实现共享资源的串行化从而保证多线程安全。

**锁实现**

Java 中实现锁的方式有很多，如：synchronized 关键字实现锁；ReentrantLock 可重入锁，相比 synchronized，可重入锁提供了更灵活的控制，需要自己手动释放锁，同时提供了可中断，可定时的能力；ReadWriteLock 读写锁，通过读写分离的机制，减少锁竞争提升系统并发能力。

通过锁可以实现共享可变数据的线程安全，但是在高并发的场景下可能因激烈的竞争导致并发能力下降。

**锁的常用优化策略**

- **减少锁的持有时间**：在锁竞争的过程中，单个线程对锁的持有时间和性能有着直接关系。如果单线程持有锁的时间过长，那么锁的竞争程度也就越激烈。因此，在系统开发过程中尽量减少锁的持有时间。
- **减少锁的粒度**：减少锁粒度也是降低多线程锁竞争的一种有效手段，这种技术典型的应用场景就是ConcurrentHashMap 对 Collections.synchronizedMap() 的优化。LinkedBlockingQueue 中将 put 和 take 分别有自己的锁，实现分离。
- **volatile**：关键字实现无锁安全的线程共享。
- **AtomicXX**：原子类变量使用。
- **CAS 思想**：实现无锁的线程安全访问。
- **Amino 框架**：提供了很多无锁线程安全的数据结构。

### 3. 系统优化—JVM 调优

关于 Java 应用的系统优化，JVM 调优是其核心点之一，而 JVM 调优最重要的工作就是 Full GC 的优化。本节将从 GC 调优原则切入介绍 GC 调优。

#### **3.1 GC 调优原则**

在调优之前，我们需要记住下面的原则：

- 多数的 Java 应用不需要在服务器上进行 GC 优化；
- 多数导致 GC 问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题；
- 在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）；
- 减少创建对象的数量；
- 减少使用全局变量和大对象；
- GC 优化是到最后不得已才采用的手段；
- 在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多。

#### **3.2 GC 调优目的**

- 将转移到老年代的对象数量降低到最小
- 减少 GC 的执行时间

#### **3.3 GC 调优策略**

**策略 1**

将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。

**策略 2**

大对象进入老年代，虽然大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配的老年代，破坏新生代的对象结构，可能会出现频繁的 Full GC。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收老说简直就是噩梦）。`-XX:PretenureSizeThreshold` 可以设置直接进入老年代的对象大小。

**策略 3**

合理设置进入老年代对象的年龄，`-XX:MaxTenuringThreshold` 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 Full GC 发生的频率。

**策略 4**

设置稳定的堆大小，堆大小设置有两个参数：`-Xms` 初始化堆大小，`-Xmx` 最大堆大小。

**策略 5**

注意：如果满足下面的指标，则一般不需要进行 GC 优化：

- Minor GC 执行时间不到 50 毫秒
- Minor GC 执行不频繁，约 10 秒一次
- Full GC 执行时间不到 1 秒
- Full GC 执行频率不算频繁，不低于 10 分钟 1 次

### 4. 系统优化—缓存设计

#### **4.1 常用缓存设计**

**分布式缓存（如 Redis）**

采用分布式缓存很好的解决了数据一致性问题，所有业务系统共享分布式缓存系统数据。但稳定性和效率相对于本地缓存来说会低一些。

**本地缓存（如 Guva Cache、Map）**

本地缓存虽然效率较高，但是各服务器拥有自己的缓存数据，不是共享的，数据一致性的问题很难解决。大都通过定时任务定时刷新来保证数据准确性，同时，本地缓存还有内存限制，不易存储大量数据，适用于存储读多写少的公共数据。

通常，缓存最重要的问题是如何保证缓存数据与 DB 数据的一致性。缓存数据一致性解决方案：

1. 可以在本服务器启动定时任务，定时刷新来保证数据的一致性；
2. 可以在缓存数据中添加时间戳，每次读取数据之后根据时间判断是否有效然后进行刷新；
3. 当 DB 数据发生变化时，可以通过广播的方式让缓存及时刷新，保证数据的一致性。

#### **4.2 缓存对象设计**

**缓存对象粒度**

对于本地磁盘或分布是缓存系统来说，其缓存的数据一般都不是结构化的，而是半结构化或序列化的。这就导致了我们读取缓存时，很难直接拿到程序最终想要的结果。那么，缓存对象中到底如何存放数据呢：一种数据一个对象，简单，读取写入都快，但是种类一多，缓存的管理成本就会很高；多种数据放在一个对象里，方便，一块全出来了，想用哪个都可以，但如果只需要其中一种数据，其它的就浪费了，网络带宽和传输延迟的消耗也很可观。

综上分析，不同的业务场景应使用不同的缓存粒度，折衷权衡。缓存一般都是访问频率非常高的数据，各个点的累积效应可能是非常巨大的！当然，有些缓存系统的设计也要求我们必须考虑缓存对象的粒度问题，比如说 Memcached，其 chunk 设计要求业务要能很好的控制其缓存对象的大小，淘宝的 Tair 也是，对于尺寸超过 1M 的对象，处理效率将大为降低。

像 Redis 这种提供同时提供了 Map、List 结构支持的系统来说，虽然增加了缓存结构的灵活性，但最多也只能算是半结构化缓存，还无法做到像本地内存那样的灵活性。

粒度设计的过粗还会遇到并发问题。一个大对象里包含的多种数据，很多地方多要用，这时如果使用的是缓存修改模式而不是过期模式，那么很可能会因为并发更新而导致数据被覆盖，版本控制是一种解决方法，但是这样会使缓存更新失败的概率大大增加，而且有些缓存系统也不提供版本支持（比如说用的很广泛的 Memcached）。

**缓存对象结构**

对于一个缓存对象来说，并不是其粒度越小，体积就越小。如果你的一个字符串就有 1M 大小，那也是很恐怖的。数据的结构决定着你读取的方式，举个很简单的例子，集合对象中，List 和 Map 两种数据结构，由于其底层存储方式不同，所以使用的场景也不一样：前者更适合有序遍历，而后者适合随机存取。回想一下，你是不是曾经在程序中遇到过为了合并两个 list 中的数据，而不得不循环嵌套? 所以，根据具体应用场景去为缓存对象设计一个更合适的存储结构，也是一个很值得注意的点。

#### **4.3 缓存更新策略**

缓存的更新策略主要有两种：被动失效和主动更新，下面分别进行介绍。

**被动失效**

一般来说，缓存数据主要是服务读请求的，并设置一个过期时间；或者当数据库状态改变时，通过一个简单的 delete 操作，使数据失效掉；当下次再去读取时，如果发现数据过期了或者不存在了，那么就重新去持久层读取，然后更新到缓存中，这即是所谓的被动失效策略。

但是在被动失效策略中存在一个问题，就是从缓存失效或者丢失开始直到新的数据再次被更新到缓存中的这段时间，所有的读请求都将会直接落到数据库上，而对于一个高访问量的系统来说，这有可能会带来风险。所以我们换一种策略就是，当数据库更新时，主动去同步更新缓存，这样在缓存数据的整个生命期内，就不会有空窗期，前端请求也就没有机会去亲密接触数据库。

**主动更新**

前面我们提到主动更新主要是为了解决空窗期的问题，但是这同样会带来另一个问题，就是并发更新的情况：在集群环境下，多台应用服务器同时访问一份数据是很正常的，这样就会存在一台服务器读取并修改了缓存数据，但是还没来得及写入的情况下，另一台服务器也读取并修改旧的数据，这时候，后写入的将会覆盖前面的，从而导致数据丢失。这也是分布式系统开发中，必然会遇到的一个问题。解决的方式主要有两种：

- **锁控制**

这种方式一般在客户端实现(在服务端加锁是另外一种情况)，其基本原理就是使用读写锁，即任何进程要调用写方法时，先要获取一个排它锁，阻塞住所有的其它访问，等自己完全修改完后才能释放。如果遇到其它进程也正在修改或读取数据，那么则需要等待。 锁控制虽然是一种方案，但是很少有真的这样去做的，其缺点显而易见，其并发性只存在于读操作之间，只要有写操作存在，就只能串行。

- **版本控制**

这种方式有两种实现，一种是单版本机制，即为每份数据保存一个版本号，当缓存数据写入时，需要传入这个版本号，然后服务端将传入的版本号和数据当前的版本号进行比对，如果大于当前版本，则成功写入，否则返回失败。这样解决方式比较简单，但是增加了高并发下客户端的写失败概率。

还有一种方式就是多版本机制，即存储系统为每个数据保存多份，每份都有自己的版本号，互不冲突，然后通过一定的策略来定期合并，再或者就是交由客户端自己去选择读取哪个版本的数据。很多分布式缓存一般会使用单版本机制，而很多 NoSQL 则使用后者。

#### **4.4 数据对象序列化**

由于独立于应用系统，分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一。一般来说，我们对一个序列化框架的关注主要有以下几点：

1. 序列化速度，即对一个普通对象，将其从内存对象转换为字节数组需要多长时间，这个当然是越快越好；
2. 对象压缩比，即序列化后生成对象的与原内存对象的体积比；
3. 支持的数据类型范围，序列化框架都支持什么样的数据结构，对于大部分的序列化框架来说，都会支持普通的对象类型，但是对于复杂对象(比如说多继承关系、交叉引用、集合类等)可能不支持或支持得不够好；
4. 易用性，一个好的序列化框架必须也是使用方便的，不需要用户做太多的依赖或者额外配置。

序列化可选框架：Java 源生序列化、Google Protobuf、Hessian、Kryo。

### 5. 总结

Java 系统性能优化涉及面非常广，本系列上、下两篇文章介绍了 Java 系统性能优化的一些主流优化路线和方法，限于文章篇幅且考虑到读者应已具备 Java 相关基础知识，行文中很多细节并没有展开叙述。如果读者 Java 基础薄弱，阅读起来可能存在困难，建议读者针对不理解的内容多查阅资料，也可以通过 GitChat 平台向我提问。