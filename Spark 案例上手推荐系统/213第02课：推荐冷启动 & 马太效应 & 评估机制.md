# 2/13第02课：推荐冷启动 & 马太效应 & 评估机制

在第01课中，我们对于推荐系统涉及到的一些技术范畴，以及相关的概念进行了梳理，并且对于常见的推荐算法进行了相应了解。

接下来将继续完善我们对于推荐系统涉及的相关基础常识，包括冷启动机制、马太效应的产生，以及推荐系统的评估体系等。

### 推荐中冷启动的问题解决

所谓冷启动，即在推荐系统初期时，没有任何用户与物品的交集信息，即无用户的行为轨迹，无法通过类似协同或者用户偏好等方式进行推荐，这种时候，我们就称推荐系统处于冷启动状态。

这种情况，我们需要尽快的累积起第一批用户行为轨迹。我们可以通过基于内容的推荐，或者做一些其他类似的操作，快速有效的进行物品推荐。一段时间后，累积到一定的用户行为时，整个系统就能够正常使用协同过滤等方式进行推荐了。

但是，针对于新加入的用户，或者新加入的物品，同样也是出于冷启动状态的，这个时候，需要对这种物品或者用户做特殊的处理。

除了基于内容属性的推荐，我们还有其他的一些策略用于弥补这种行为数据不足的情况，比如典型的热度模型，推荐热点信息这种行为虽然 low，但是从整体的反馈来看，还是有一定效果的，此外，还可以根据一些统计学上的结论，进行基于统计分析结论的推荐。

除此之外，我们也可以通过其他渠道收集用户的数据，比如用户注册的时候所填写的个人资料，这些都是可以作为推荐的原始依赖数据。

#### Bandit 算法

在这里，重点介绍一种冷启动中常用的算法，那就是 Bandit 算法，又俗称老虎机算法。

一个玩家要去玩老虎机，一排老虎机，外表都是一样的，但每个老虎机吐钱的概率是不同的，我们不知道每个老虎机吐钱的概率是如何分布的，并且需要考虑如何获取最大化的收益；然后会采用多臂尝试的手段，即有策略的逐一进行探测，即 MAB 问题的解决（Multi-armed bandt problem，K-armed bandit problem）。

具体的过程如下：

- 用有限个类别来表示用户的每个兴趣，这也就是 MAB 问题的 Arm。
- 通过几次实验之后（推荐反馈），来计算新用户对每个类别的感兴趣概率。
- 经历“选择-评估-更新-选择”的循环测试之后，理论上最终的选择会越来越逼近用户真正感兴趣的类别。

实际上我们会发现，这就是一个动态选择，并且不断通过反馈来更新选择的过程，这种算法某种意义上能够解决一定程度上的冷启动问题。

### 马太效应

马太效应或者说长尾效应，即热者愈热，实际举例来说就是，在实际的购买场景中，由于你推荐的次数越多，部分优质的商品购买或者点击的次数就越多，形成的用户购买轨迹就越多，所以得到的推荐机会就越多，进而产生的推荐也越多，变得越热。

随着不断迭代，子子孙孙无穷尽也，这样得到推荐的商品就会集中在少部分商品中，而大部分长尾商品是沉寂的，一个推荐系统如果长时间处于长尾效应中，造成推荐疲劳，其推荐效果就会减弱。

所以，一个好的推荐系统，要考虑到适当的挖掘长尾商品，通过真的个性化，把适当的长尾商品送到真正需要他们的人手里，在实际的操作过程中，我们可以适当的进行热度降权，从而让一些中下层的商品得到更多的曝光机会，当然前提是保证点击率的情况下。

另外一个场景会形成马太效应的是热度模型，即我们的热度榜单，长时间的高居榜首，一定会获得更多的点击，而点击越多其热度越高，但我们的信息是需要保持新鲜度的，不然点击率迟早会下架的。

所以，我们使用一些机制让处于头部的商品或者信息降权，时间衰减是一个比较通用的做法，即随着时间的迁移，其整体热度会不断的下降，至于说下降的方式，速率就看模型的设计了。

### 如何评估一个推荐系统的好坏

我们做一个推荐系统，需要为推荐系统的效果所负责，只有良性的推荐才能为整个业务带来正向的作用，不好的推荐可能反倒是一种增加用户信息冗余度的行为。

在评估推荐结果的好坏的过程中，最直接的体现就是用户的反馈操作，其中反馈又分为显式反馈和隐式反馈。

#### 隐式反馈

所谓隐式反馈，即用户并不会显式的告诉你，你推荐的东西我不喜欢或者喜欢，只是通过其点击与否来隐式的告诉你他对推荐结果的满意情况。

所以，这种反馈实际上就是收集用户对于曝光推荐列表的点击操作，然后将这种操作上报到系统后台，用于我们做后续推荐算法的持续优化。

#### 显式反馈

相对于隐式反馈，显式反馈则是通过产品形态的设计，让用户很确认的告诉你，他对于推荐列表是喜欢还是厌恶，这种反馈结果会更加的明确。

并且显式反馈的操作方式很多时候也会用于广告的投放，比如谷歌投放的页面广告，他提供了关闭的按钮，并且再关闭的时候会建议勾选因为什么不喜欢。

同样在很多的推荐列表中，系统设计同样允许你对于推荐结果进行评判，喜欢还是不喜欢。

不过不一定所有的推荐系统都会考虑设计显式反馈信息的收集，毕竟这对于用户来说是个高成本的操作行为，所以相对会比较难收集到很多有用信息。

#### 推荐的评估指标

一说到对于推荐系统的评估指标，很多立马想到了推荐的准确率、召回率，以及非准确性指标诸如推荐的多样性、新颖性等诸如此类。

这里有必要解释一下这几个指标，所谓准确率就是推荐的准确情况，反馈出来最直接的体现就是推荐点击转化有多少，而所谓的召回率则是测试集中有多少用户喜欢的物品出现的推荐列表中，即召回了多少商品，两者一融合又出现典型的评估方式F值。

而所谓多样性，从理论上说我们的整体推荐列表其相似程度应该越低，这样我们就可以将候选范围尽可能的扩大，这是有一定道理的。

而新颖性则是挖掘长尾的利器，即推荐给用户一些不常见但是又恰巧合适的商品，这里又跟惊喜度挂钩了，即给用户带来多大的惊喜度。

但我个人认为，以上说的这些都太官方了，除了准确率这个维度相对靠谱，其他的都是锦上添花的评估，我个人认为一个好的推荐系统应该老老实实结合其业务诉求以及长远持续的角度来思考。

举个简单例子，如果你是一个电商网站，其推荐系统的直接效果就是点击转化，或者说 99% 的推荐场景其最直接的体现就是点击转化。

但是，显然还不够。对于电商的商业模式来说，我们最终希望的 GMV 成交，所以推荐落实到最本质的诉求上就是带来更多额外的 GMV，这就是最本质的评估指标。

当然再往上层追溯，就是点击转化率、浏览的深度、DAU 转化率等。

对于资讯型以及内容型的推荐来说，除了点击转化，还看重如何让用户更时间的侵入其中，同样有浏览深度、浏览时长、付费转化等。

对于上述我们说的官方指标，比如新颖性之类的，到底有没有用呢，肯定是有用的，比如如果系统无法给我们长时间带来惊喜，那么可能这个转化就会降低，你会发现最终又会落实到 GMV 或者浏览深度上面去。

所以，我个人认为，诸如新颖性这种维度，不应该把他当成一个指标，但是应该当成一个设计推荐系统时不可或缺的一种思考因素，以便让你的推荐效果更好，以及效果更持久。

#### 评估模式

说完指标，我们再来聊如何评估，一方面是通过历史已有的点击数据，来做离线评测，这个应该相对好理解，历史数据都有了，有没有推出来，再对应有没有点击，一目了然。

但实际上，生产环境的情况可能会复杂，所以单纯依赖于离线的评估有时候效果并不是很准确，这就涉及到了在线评估的问题。

即我们常说的 ABTest 系统，又或者叫在线实验平台，即我们通过控制分流的方式，来实验我们的新模型、新算法、新策略，然后根据指标的变化，来最终决定使用哪个或者说哪些算法模型的融合。

由于测试流量的可控，所以这种方式既“环保”又准确，深受广大推荐系统的技术猿们的喜爱，在后续我们讲工程架构的时候将会重点讲解这个实验平台。

#### 信息茧房

承接上面新颖性以及多样性的问题，大家如果关注互联网科技新闻，在前一段时间，XX 日报就曾就“信息茧房”的问题批判过某条，说其推荐引擎导致了用户的信息茧房，不利于用户的信息获取的扩展等。

所谓的信息茧房就是，系统不断的给你推荐东西，然后你不断的点击，然后系统就会越来越多获取到你的兴趣爱好特征，然后再根据你的兴趣特征再给你推荐东西，然后再点击再推荐，子子孙孙无穷尽也。

通过这种循环，系统会越来越懂你，知道你喜欢什么就给你推什么，然后你会发现最终你的信息获取范围会缩减到一定的范围，越来越小，“作茧自缚”。

信息茧房的出现可能对于单纯的点击转化可能是一个正向的作用，如果不是正向作用机器也不会做如此选择了，但是从某种程度来说，比如人的角度来说，这种情况的出现就不一定是好事了，这也就是某日报为何要匹配某条的原因。

信息茧房也是可以解决的，正如上面所说的，我们在关注转化指标的时候，适当考虑推荐的多样性以及新颖性，实际上是可以一定程度上解决这个问题的。

到此，我们涉及到推荐相关的基础知识基本上已经聊过了，在接下来的章节里，我们将针对上述我们说的推荐算法进行深入讲解，结合具体的工程代码案例，来进一步学习相关的推荐算法，然后再从整体全局的算法架构，以及工程架构的维度来将整个体系串起来。