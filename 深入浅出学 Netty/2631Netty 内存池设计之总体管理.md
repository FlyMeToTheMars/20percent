# 26/31Netty 内存池设计之总体管理

### 引言

前文我们分析了内存分配的相关算法，以及其在 Netty 当中的变种和代码实现。之前在内存块中申请内存，申请大小都大于一个内存页的大小。而如果在申请大小小于一个内存页时也分配一个内存页，就显得很浪费了。为此，Netty 设计了专门的子页分配算法，用于处理小内存的分配场景。

### 子页管理算法

对于小于一个内存页大小的内存申请，首先也是需要在内存块上执行申请的，成功后就会得到一个内存页的空间。现在的问题就转化为一个内存页的空间上，如何避免小内存的申请而浪费一个内存页的剩余空间。最容易的想到的就是，将小内存也按照内存块的算法分配思路再来一次。不过内存块的分配算法是需要额外的空间来存储元数据信息（二叉树节点相关信息），如果对于内存页也采用这种模式，元数据信息的开销相比于内存页本身的大小，占比太高太不划算，显然不能采用这种方式。

在 Netty 中，对于小内存的分配，是将一个内存页按照小内存的大小，拆成相同大小的 N 份，将这种模式下的内存页称之为子页。在 Netty 的内存申请中，所有的申请大小都是按照 2 的次方幂进行规范化处理的。因此将一个内存页拆分等分的 N 份，后续仍然会遇到相同大小的小内存申请，就可以直接从这个子页中进行分配，而不需要从内存块中再次申请一个新的内存页，提升了内存页的利用率。

例如说，一个内存页为 8k 的大小，如果在内存块中申请 512 大小的内存。假设申请时内存块给分配了一个新的内存页，则内存页会按照 512 大小进行等分，并且最终给出其中 512 大小的区域供 ByteBuf 使用。等分后，内存页会变成如下的样子：

![img](https://markdownpic-1251577930.cos.ap-chengdu.myqcloud.com/20191230142318.png)

其中绿色代表已经分配。而这个内存页后续可以持续参与到 512 大小的内存申请中，直到以下两个事件发生：

- 按照 512 等分的内存页已经全部被分配完毕，则无法继续分配。
- 内存页上分配的区域已经全部被归还，则该内存页按照内存块中的回收流程，回收至内存块中。

对于等分后的内存页，每一个等分只有 2 种状态：使用中，未使用。为了减少管理的开销，Netty 中采用位图的思路来管理整个等分的内存页。位图，简单的来说，就是通过每一个比特位来标识一个信息。由于比特位只有 0 和 1 两种取值，因此很适合于管理是或者否的逻辑。一个 long 变量，由 8 个字节，64 个比特位构成，因此最大可以管理 64 个等分的使用信息。

基于上述前提，我们可以将子页的分配算法总结如下：

- 将申请大小规范化，称之为规范大小。如果规范大小小于内存页大小，则走子页分配模式。
- 如果内存块中存在已经处于子页分配模式，且分配大小等于规范大小的内存页，则直接从子页上申请一份区域用于分配；此时分配结束。否则首先从内存块上申请一个全新的内存页，当成子页使用。
- 内存页申请成功的情况下，按照规范大小将内存页的空间等分。按照等分个数，使用位图方式管理每一个等分的使用信息。从全部等分中，获取一份可用的等分，标记其位图坐标为 1，表示使用中。使用该内存区域初始化 ByteBuf。
- 将该子页放在“内存池”中管理。后续如果有相同规范大小的申请，则优先尝试从未全部分配的子页上获取。
- 每次从子页取走一个等分用于内存使用时，对应的位图标志位设置为 1；当该等分被归还时，对应的位图标志位复位回 0。

通过对内存页的大小等分和位图管理方式，有效的提高了在小内存申请情况下，内存页的利用率。

### 内存池

聊完了子页分配算法，我们再来内存池的整体分配逻辑。小内存的申请与归还实际上由内存池自身负责，而不是在内存块中完成，因此这里将子页分配和内存池的整体管理放在一起阐明。

内存池是内存申请与分配的入口，内存池本身不参与内存的分配，但是其负责管理内存块和用于共享的按照小内存申请大小等分后的子页。

#### 内存块管理

先说对内存块的管理。在内存池中，存储着一定数量的内存块。Netty 使用 PoolChunkList 内存块列表来存储 PoolChunk 内存块。PoolChunk 内部有属性 next 和 prev，用于指向自己的前驱和后继节点。而 PoolChunkList 中则存储着 PoolChunk 链表的头结点。此外，PoolChunkList 自身也通过 nextList 和 prevList 属性构成了一个双向链表。用图的方式来形象表达就是：

![img](https://markdownpic-1251577930.cos.ap-chengdu.myqcloud.com/20191230222815.png)

在同一个 PoolChunkList 中的 PoolChunk，都是有着相同的使用率。在内存池中，管理着 6 个使用率区间的 PoolChunkList，分别是：

- qInit：存储着使用率 0%~25% 的 PoolChunk
- q000：存储着使用率 1%~50% 的 PoolChunk
- q025：存储着使用率 25%~75% 的 PoolChunk
- q050：存储着使用率 50%~100% 的 PoolChunk
- q075：存储着使用率 75%~100% 的 PoolChunk
- q100：存储着使用 100%~100% 的 PoolChunk

PoolChunk 的内存使用率随着内存的申请和归还不断变化着，当 PoolChunk 的内存使用率到达所在 PoolChunkList 管理的上限时则移动到下一个 PoolChunkList，如果到达下限时则移动到前一个 PoolChunkList。

我们可以看到，PoolChunkList 负责的使用率区间是有重叠的部分，这是为了避免 PoolChunk 的使用率在临界线附近时反复在相邻的 PoolChunkList 移动造成。在上述示意图中我们可以看到，p000 这个 PoolChunkList 是没有前向节点的。Netty 的考虑是，当其余 PoolChunkList 中没有合适的 PoolChunk 可以分配内存时，则创建一个新的 PoolChunk，放入 pInit 中，并且分配内存。而在 p000 中的 PoolChunk，如果因为内存归还的原因，使用率下降到 0%，则不需要放入 pInit，直接执行销毁方法，将整个内存块的内存释放掉。这样子，在内存池中的内存块就有生成，有销毁。避免了在没有使用的情况下仍然还占据着内存的情况。

有了 PoolChunkList 的结构后，从 PoolChunkList 中分配内存实际上很简单，其步骤如下：

- 从头节点的 PoolChunk 开始，执行`PoolChunk#allocate`，如果成功，则停止；否则选择下一个 PoolChunk 继续尝试分配。
- 如果分配成功，则计算该 PoolChunk 的使用率，使用率超过 PoolChunkList 的上限时，移动到下一个 PoolChunkList。

根据上述的数据结构，Netty 在内存池 PoolArena 中申请内存的流程可以抽象如下

![img](https://markdownpic-1251577930.cos.ap-chengdu.myqcloud.com/20190805111022.png)

上面的流程申请的内存大小从内存页到内存块的大小。而当申请的内存大小大于一个内存块时，内存池则会创建一个特殊的内存块对象。该 PoolChunk 对象本身的大小就是申请的大小，且该 PoolChunk 对象本身并不会加入内存池的管理。该对象内部也没有用于池化管理的二叉树等一系列用于分配释放的数据结构，只是简单的包装了一段内存空间。是为了保持在 ByteBuf 上初始化内存空间的 API 一致性。而该特殊的内存块内部的非池化标志位 unpooled 为 true，这使得在依靠 Arena 将 ByteBuf 空间归还给 PoolChunk 时，可以快速的识别出该 PoolChunk 不需要池化管理，从而快速的执行内存释放动作。

#### 子页管理

前文说到，内存池负责管理着被用于分配小内存的子页。为了有效的使用内存页用于小内存的分配，Netty 中将小于一个内存页大小的申请大小规范化为两种类型：

- 从 16 到 512 的大小，规范为不小于申请大小的 16 的倍数大小。
- 对于大于 512 小于一个内存页的大小，规范为不小于申请大小的 2 的次方幂大小。

用于存储小内存管理相关元数据信息的对象，包含有位图信息，等分大小，对应的内存页的二叉树节点下标等，在 Netty 中定义为子页 PoolSubPage。

Netty 中对子页的管理方式是相同等分大小的子页使用 next、prev 属性形成一个双向链表。而对于从 16 到内存页大小 / 2 的每一个允许的等分大小，Netty 都分配了一个空的子页对象用作双向双向链表的头结点。这些不同等分大小的头结点都在 PoolArena 的子页数组中存储着。

因为小内存的大小申请会以 512 为分界线进行两种不同的大小规范化，因此在 Netty 中，为了管理这两种大小情况，使用两个不同的 PoolSubPage 数组来分别存储这些用作头结点的 PoolSubPage 对象，分别是：

- tinySubpagePools：数组长度固定为 512/16=32，其负责存储大小从 16 开始，按照 16 递增至 512 （不包含）的 PoolSubPage 头结点。
- smallSubpagePools：数组长度为从 512 开始，2 倍递增至内存页大小（不包含）的 PoolSubPage 头结点。

当一个子页全部空间都被分配完毕时，会从内存池管理的子页链表中摘除。而当其有空间时，则会再次被放入链表中。如果一个子页的全部空间都没有被使用，则会将该子页从链表中摘除，并且将内存空间归还给对应的内存块。而如果链表中仅剩余一个子页，即使其没有被使用，也不会被摘除和归还。

申请一个小内存时，首先通过规范大小找到对应的子页数组，然后再找到对应大小的头结点子页对象，在这个头结点连接的链表上，获得子页进行空间分配。如果链表上没有可用的子页，则在内存块上申请一个内存页，并且将其子页化后，再通过子页进行空间分配，并且将该子页放入到链表中。

### 线程缓存

内存池上的内存分配算法，是一个单线程的算法。为了保证并发安全，在执行分配的时候需要以内存池 PoolArena 为对象进行加锁。在网络应用中，内存的申请与归还是一个非常频繁的操作。而多线程对同一个对象的锁竞争对应用的性能有较大的负面影响。为了进一步提高性能，规避锁竞争是一个很容易想到的努力方向，而规避锁竞争常见的手段主要是无锁算法和线程变量模式。显然，将内存池的算法改造为无锁算法是很困难的，因此 Netty 中采用了线程变量的方式来规避锁竞争。

简单的说，Netty 额外引入了线程缓存的方式。通过线程变量，按照三种规范化的大小保存了一定数量的内存空间，三种规范化大小分别是：

- 从 16 按照 16 为步长递增至 512 的规范化大小。
- 从 512 按照 2 倍步长递增至内存页大小的规范化大小。
- 从内存页大小按照 2 倍步长递增至指定大小的规范化大小。

线程缓存会按照这三种大小分类，针对其中每一个大小存储一定数量的内存区域。当应用程序需要申请内存空间时，优先从线程缓存中分配。如果线程缓存中没有，则对内存池执行加锁操作后，从内存池中分配。而当需要归还申请的内存空间时，优先将内存空间缓存到线程缓存中。如果线程缓存针对该分配大小已经达到了存储上限或者该分配大小不缓存在线程缓存中，则将该内存空间归还至内存池中。

梳理了内存块，内存页，小内存分配，线程缓存这些数据结构后，就可以完整的展示内存池的内存分配逻辑，如下：

![img](https://markdownpic-1251577930.cos.ap-chengdu.myqcloud.com/20191231011930.png)

### 总结与思考

这篇文章我们梳理了 Netty 中对于内存分配的总体管理思路，介绍了内存池，小内存管理，线程缓存等相关概念和数据结构。并且从其实现的算法层面上梳理了其重点的步骤流程。那么在下一个章节中，我们将会从代码的角度进一步详细的分析其具体的实现。